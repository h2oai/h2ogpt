# GPT4ALL or llama-cpp-python model_kwargs

# GPT4ALl GPT-J type, from model explorer choice, so downloads
model_name_gptj=ggml-gpt4all-j-v1.3-groovy.bin

# llama-cpp-python type, supporting version 3 quantization, here from locally built llama.cpp q4 v3 quantization
# below uses prompt_type=wizard2
model_path_llama=WizardLM-7B-uncensored.ggmlv3.q8_0.bin
# below assumes max_new_tokens=256
n_ctx=1792
# uncomment below if using llama-cpp-pyton with cublas built in
# n_gpu_layers=20

# GPT4ALl LLaMa type, supporting version 2 quantization, here from model explorer choice so downloads
model_name_gpt4all_llama=ggml-wizardLM-7B.q4_2.bin

# PDF_CLASS_NAME=UnstructuredPDFLoader

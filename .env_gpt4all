# GPT4ALL or llama-cpp-python model_kwargs

# GPT4ALl GPT-J type, from model explorer choice, so downloads
model_name_gptj=ggml-gpt4all-j-v1.3-groovy.bin

# llama-cpp-python type, supporting version 3 quantization, here from locally built llama.cpp q4 v3 quantization
# below uses prompt_type=wizard2
model_path_llama=WizardLM-7B-uncensored.ggmlv3.q8_0.bin
# below assumes max_new_tokens=256
n_ctx=1792

# GPT4ALl LLaMa type, supporting version 2 quantization, here from model explorer choice so downloads
model_name_gpt4all_llama=ggml-wizardLM-7B.q4_2.bin

PDF_CLASS_NAME=UnstructuredPDFLoader
